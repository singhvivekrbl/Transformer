{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded1917495 word vectors.\n"
     ]
    }
   ],
   "source": [
    "def load_glove_embeddings(file_path):\n",
    "    embeddings_index ={}\n",
    "    with open(file_path,'r',encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:],dtype = 'float32')\n",
    "            embeddings_index[word] = coefs\n",
    "        return embeddings_index\n",
    "    \n",
    "# path to the download Glove file\n",
    "glove_file_path = 'C:\\\\Users\\\\singh\\\\OneDrive\\\\Desktop\\\\Transformer\\\\Embedding_model\\\\glove.42B.300d.txt'\n",
    "embeddings_index = load_glove_embeddings(glove_file_path)\n",
    "print(f\"Loaded{len(embeddings_index)} word vectors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = [\"The\", \"cat\", \"sat\", \"on\", \"the\", \"mat\"]\n",
    "vocab = {\"The\": 0, \"cat\": 1, \"sat\": 2, \"on\": 3, \"the\": 4, \"mat\": 5}\n",
    "tokenized_document = [vocab[word] for word in document]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 300\n",
    "vocab_size = len(vocab)\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "\n",
    "for word,i in vocab.items():\n",
    "    embedding_vector=embeddings_index.get(word.lower())\n",
    "    if embedding_vector is not None:\n",
    "        ## words not found in embedding index will be all zeros\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Document: [0, 1, 2, 3, 4, 5]\n",
      "Embedded Document:\n",
      " tensor([[-0.2084, -0.1493, -0.0175,  ..., -0.5407,  0.2120, -0.0094],\n",
      "        [ 0.2111,  0.2176, -0.5264,  ..., -0.1508, -0.2406, -0.0514],\n",
      "        [-0.5258, -0.2272,  0.5184,  ..., -0.0066,  0.0792,  0.0965],\n",
      "        [ 0.0006,  0.0486,  0.4897,  ...,  0.1373,  0.1387,  0.3140],\n",
      "        [-0.2084, -0.1493, -0.0175,  ..., -0.5407,  0.2120, -0.0094],\n",
      "        [ 0.0889,  0.1926,  0.2956,  ..., -0.3158,  0.1696, -0.3886]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Create the embedding layer\n",
    "embedding_layer = nn.Embedding(num_embeddings = vocab_size, embedding_dim = embedding_dim)\n",
    "embedding_layer.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype = torch.float32))\n",
    "\n",
    "#Freeze the embedding layer\n",
    "embedding_layer.weight.requires_grad = False\n",
    "\n",
    "#Convert tokenized document to a tensor\n",
    "tokenized_document_tensor = torch.tensor(tokenized_document, dtype=torch.long)\n",
    "\n",
    "# Get the embeddings for the document\n",
    "embedded_document = embedding_layer(tokenized_document_tensor)\n",
    "\n",
    "print(\"Tokenized Document:\", tokenized_document)\n",
    "print(\"Embedded Document:\\n\", embedded_document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation\n",
    "__1. Load GloVe Embeddings:__ The load_glove_embeddings function reads the GloVe file and stores the embeddings in a dictionary.\n",
    "\n",
    "__2. Prepare Document and Vocabulary:__ Convert the document into a list of indices based on a predefined vocabulary.\n",
    "\n",
    "__3. Create Embedding Matrix:__ For each word in the vocabulary, retrieve the corresponding GloVe embedding and store it in the embedding matrix. Words not found in GloVe are initialized to zero vectors.\n",
    "\n",
    "__4. Embedding Layer in PyTorch:__ Create an nn.Embedding layer and initialize it with the pre-trained embedding matrix. Optionally, freeze the embedding layer if you do not want to update these embeddings during training.\n",
    "\n",
    "__5. Get Embeddings:__ Convert the tokenized document to a tensor and pass it through the embedding layer to get the corresponding embeddings.\n",
    "\n",
    "## Next Steps\n",
    "After embedding your document with pre-trained embeddings, you can proceed to use these embeddings in more complex models like the Transformer encoder or decoder. If you need further assistance on any specific part of building these models, feel free to ask!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['the', 'cat', 'sat', 'on', 'the', 'mat', 'the', 'mat', 'was', 'blue']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Simple tokenization and preprocessing\n",
    "def preprocess_document(doc):\n",
    "    doc = doc.lower()  # Convert to lowercase\n",
    "    doc = re.sub(r'[^\\w\\s]', '', doc)  # Remove punctuation\n",
    "    tokens = doc.split()  # Tokenize by splitting on whitespace\n",
    "    return tokens\n",
    "\n",
    "document = \"The cat sat on the mat. The mat was blue.\"\n",
    "tokens = preprocess_document(document)\n",
    "print(\"Tokens:\", tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Matrix:\n",
      " [[-2.08379999e-01 -1.49320006e-01 -1.75279994e-02 ... -5.40660024e-01\n",
      "   2.11989999e-01 -9.43570025e-03]\n",
      " [ 2.11099997e-01  2.17629999e-01 -5.26380002e-01 ... -1.50759995e-01\n",
      "  -2.40640000e-01 -5.13649993e-02]\n",
      " [-5.25780022e-01 -2.27190003e-01  5.18419981e-01 ... -6.55960012e-03\n",
      "   7.91649967e-02  9.64530036e-02]\n",
      " ...\n",
      " [ 8.89369994e-02  1.92560002e-01  2.95569986e-01 ... -3.15770000e-01\n",
      "   1.69609994e-01 -3.88570011e-01]\n",
      " [-4.21999991e-02 -4.44139994e-04  5.28949983e-02 ... -8.49580020e-02\n",
      "  -1.19060002e-01 -4.98100013e-01]\n",
      " [-1.69119999e-01 -7.01619983e-01 -2.12990001e-01 ... -2.15650007e-01\n",
      "   7.91009981e-03 -4.21869993e-01]]\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 300  # GloVe embedding dimension\n",
    "embedding_matrix = np.zeros((len(tokens), embedding_dim))\n",
    "\n",
    "for i, word in enumerate(tokens):\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "print(\"Embedding Matrix:\\n\", embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: Collection word_embeddings already exists\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "\n",
    "# Initialize Chroma DB client\n",
    "client = chromadb.Client()\n",
    "\n",
    "# Delete existing collection if it exists\n",
    "collection_name = 'word_embeddings'\n",
    "if collection_name in client.list_collections():\n",
    "    client.delete_collection(name=collection_name)\n",
    "    time.sleep(5)  # wait for 5 seconds\n",
    "\n",
    "# Create a new collection\n",
    "try:\n",
    "    collection = client.create_collection(name=collection_name)\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 10 embeddings in Chroma DB.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Add embeddings to the collection\n",
    "for i, word in enumerate(tokens):\n",
    "    embedding_vector = embedding_matrix[i].tolist()\n",
    "    collection.add([str(i)], [embedding_vector], [{'word': word}])\n",
    "\n",
    "print(f\"Stored {len(tokens)} embeddings in Chroma DB.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: cat, Distance: 0.0\n",
      "Word: blue, Distance: 56.634735107421875\n",
      "Word: mat, Distance: 61.52752685546875\n",
      "Word: mat, Distance: 61.52752685546875\n",
      "Word: the, Distance: 66.46363067626953\n",
      "Word: the, Distance: 66.46363067626953\n",
      "Word: the, Distance: 66.46363067626953\n",
      "Word: was, Distance: 67.02333068847656\n",
      "Word: on, Distance: 71.3979263305664\n",
      "Word: sat, Distance: 72.578369140625\n"
     ]
    }
   ],
   "source": [
    "# Querying the embeddings\n",
    "query_word = 'cat'\n",
    "query_embedding = embeddings_index[query_word].tolist()\n",
    "\n",
    "# Find the nearest neighbors for the query embedding\n",
    "results = collection.query([query_embedding])\n",
    "\n",
    "# Extract the words and distances\n",
    "words = results['metadatas'][0]\n",
    "distances = results['distances'][0]\n",
    "\n",
    "# Print the words and their corresponding distances\n",
    "for word, distance in zip(words, distances):\n",
    "    print(f\"Word: {word['word']}, Distance: {distance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer_embedding",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
